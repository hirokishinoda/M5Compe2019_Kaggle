{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M5 competition\n",
    "\n",
    "This competition is forecasting competition, where we aim to make correct predictions for sales 28 days in the future. Or, more precisely, 28 days in public dataset and 28 days in private dataset. When one month is left before the deadline, the labels for the 28 public days will be released.\n",
    "\n",
    "It is quite interesting that there are two competitions for the same data, the difference is in the metric and values to predict:\n",
    "* in this competition we make point forecasts and the metric is Weighted Root Mean Squared Scaled Error (WRMSSE);\n",
    "![](https://i.imgur.com/uqhsf3d.png)\n",
    "![](https://i.imgur.com/B1hglCf.png)\n",
    "* in another competition we make predictions for quantiles and the metric is Weighted Scaled Pinball Loss (WSPL)\n",
    "![](https://i.imgur.com/J8XAQP4.png)\n",
    "![](https://i.imgur.com/jzLckus.png)\n",
    "![](https://i.imgur.com/3ihaSZO.png)\n",
    "\n",
    "I plan to do some extensive EDA as I'm interested in this data! And then, of course, we will build some models.\n",
    "There is a lot of things in this data, so I'll go step by step.\n",
    "\n",
    "\n",
    "![](https://i.imgur.com/C5hASXe.png)\n",
    "\n",
    "*Work in progress :)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from scipy.signal import hilbert\n",
    "from scipy.signal import hann\n",
    "from scipy.signal import convolve\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import NuSVR, SVR\n",
    "from sklearn.metrics import mean_absolute_error, f1_score\n",
    "pd.options.display.precision = 15\n",
    "from collections import defaultdict\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cat\n",
    "import time\n",
    "from collections import Counter\n",
    "import datetime\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold, GroupKFold, GridSearchCV, train_test_split, TimeSeriesSplit, RepeatedStratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import linear_model\n",
    "import gc\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from bayes_opt import BayesianOptimization\n",
    "# import eli5\n",
    "import shap\n",
    "from IPython.display import HTML\n",
    "import json\n",
    "import altair as alt\n",
    "from category_encoders.ordinal import OrdinalEncoder\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from typing import List\n",
    "\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "import gc\n",
    "from numba import jit\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "from sklearn import metrics\n",
    "from typing import Any\n",
    "from itertools import product\n",
    "pd.set_option('max_rows', 500)\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data and overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "path = '/kaggle/input/m5-forecasting-accuracy'\n",
    "train_sales = pd.read_csv(f'{path}/sales_train_validation.csv')\n",
    "calendar = pd.read_csv(f'{path}/calendar.csv')\n",
    "submission = pd.read_csv(f'{path}/sample_submission.csv')\n",
    "sell_prices = pd.read_csv(f'{path}/sell_prices.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not surprisingly `calender` has data about dates: for each date we get info about dayofweek/week/month/year, events and flags showing whether stores allowed purchases with SNAP food stamps. We have the data for all the dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have information about item characteristics and sales for each day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sell_prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here we have information on sell prices for all items in all stores by weeks.submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our submission file should contain the forecast for the next 56 days (28 public, 28 private). We make predictions for each item in each store."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All info about a single item\n",
    "\n",
    "Let's start with looking at all the data for a single item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sales.loc[train_sales['item_id'] == 'HOBBIES_1_001']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this item (as well as all other items in fact) is sold in 10 stores in 3 states. This item belongs to `HOBBIES` category and is sold in `HOBBIES_1` department."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sell_prices.loc[sell_prices['item_id'] == 'HOBBIES_1_001']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also we have the data about sell prices in all 10 stores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's make some plots. I'd like to see sales over time in different shops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "for i in range(10):\n",
    "    plt.plot(train_sales.loc[train_sales['item_id'] == 'HOBBIES_1_002'].iloc[i, 6:].values,\n",
    "             label=train_sales.loc[train_sales['item_id'] == 'HOBBIES_1_002'].iloc[i, 5]);\n",
    "plt.title('HOBBIES_1_002 sales')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well... this doesn't look pretty. Let's make is smoother - I'll plot rolling mean over 30 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "for i in range(10):\n",
    "    plt.plot(train_sales.loc[train_sales['item_id'] == 'HOBBIES_1_002'].iloc[i, 6:].rolling(30).mean().values,\n",
    "             label=train_sales.loc[train_sales['item_id'] == 'HOBBIES_1_002'].iloc[i, 5]);\n",
    "plt.title('HOBBIES_1_002 sales, rolling mean 30 days')\n",
    "plt.legend();\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "for i in range(10):\n",
    "    plt.plot(train_sales.loc[train_sales['item_id'] == 'HOBBIES_1_002'].iloc[i, 6:].rolling(60).mean().values,\n",
    "             label=train_sales.loc[train_sales['item_id'] == 'HOBBIES_1_002'].iloc[i, 5]);\n",
    "plt.title('HOBBIES_1_002 sales, rolling mean 60 days')\n",
    "plt.legend();\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "for i in range(10):\n",
    "    plt.plot(train_sales.loc[train_sales['item_id'] == 'HOBBIES_1_002'].iloc[i, 6:].rolling(90).mean().values,\n",
    "             label=train_sales.loc[train_sales['item_id'] == 'HOBBIES_1_002'].iloc[i, 5]);\n",
    "plt.title('HOBBIES_1_002 sales, rolling mean 90 days')\n",
    "plt.legend();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what do we see here?\n",
    "* there is a definite seasonality with several peaks;\n",
    "* the sales are more or less constant and quite low (max sales per day in one store is 11);\n",
    "* as a result, it could be difficult to predict such low values;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "item_prices = sell_prices.loc[sell_prices['item_id'] == 'HOBBIES_2_001']\n",
    "for s in item_prices['store_id'].unique():\n",
    "    small_df = item_prices.loc[item_prices['store_id'] == s]\n",
    "    plt.plot(small_df['wm_yr_wk'], small_df['sell_price'], label=s)\n",
    "plt.legend()\n",
    "plt.title('HOBBIES_2_001 sell prices');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What a strange situation. I suppose there were some sales with lowered prices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All info about a single store\n",
    "\n",
    "Now that we know how the data about a single item looks like, let's have a look at one store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sales.loc[train_sales['store_id'] == 'CA_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have information about sales of 3049 various items, which belong to different categories and departments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sell_prices.loc[sell_prices['store_id'] == 'CA_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also we have the data about sell prices for all items in this store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_1_sales = train_sales.loc[train_sales['store_id'] == 'CA_1']\n",
    "pd.crosstab(ca_1_sales['cat_id'], ca_1_sales['dept_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This store (and I suppose other stores) have 3 categories: foods, hobbies and households, which have 2-3 departments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "for d in ca_1_sales['dept_id'].unique():\n",
    "    store_sales = ca_1_sales.loc[ca_1_sales['dept_id'] == d]\n",
    "    store_sales.iloc[:, 6:].sum().rolling(30).mean().plot(label=d)\n",
    "plt.title('CA_1 sales by department, rolling mean 30 days')\n",
    "plt.legend(loc=(1.0, 0.5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting that `FOODS_1` has much higher sales than any other department."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_prices = sell_prices.loc[sell_prices['item_id'] == 'HOBBIES_2_001']\n",
    "for s in item_prices['store_id'].unique():\n",
    "    small_df = item_prices.loc[item_prices['store_id'] == s]\n",
    "    plt.plot(small_df['wm_yr_wk'], small_df['sell_price'], label=s)\n",
    "plt.legend()\n",
    "plt.title('HOBBIES_2_001 sell prices');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_1_prices = sell_prices.loc[sell_prices['store_id'] == 'CA_1']\n",
    "ca_1_prices['dept_id'] = ca_1_prices['item_id'].apply(lambda x: x[:-4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "for d in ca_1_prices['dept_id'].unique():\n",
    "    small_df = ca_1_prices.loc[ca_1_prices['dept_id'] == d]\n",
    "    grouped = small_df.groupby(['wm_yr_wk'])['sell_price'].mean()\n",
    "    plt.plot(grouped.index, grouped.values, label=d)\n",
    "plt.legend(loc=(1.0, 0.5))\n",
    "plt.title('CA_1 mean sell prices by dept');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that prices on `HOBBIES_1` increase over time, but for other categories they are quite stable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All info about a single department\n",
    "\n",
    "Now we can analyse how different items of the same department are sold in different stores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sales.loc[train_sales['dept_id'] == 'HOBBIES_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sales.loc[train_sales['dept_id'] == 'HOBBIES_1', 'item_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are 416 unique items in this department and they are sold in all stores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sell_prices.loc[sell_prices['item_id'].str.contains('HOBBIES_1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hobbies_1_sales = train_sales.loc[train_sales['dept_id'] == 'HOBBIES_1']\n",
    "plt.figure(figsize=(12, 6))\n",
    "for d in hobbies_1_sales['store_id'].unique():\n",
    "    store_sales = hobbies_1_sales.loc[hobbies_1_sales['store_id'] == d]\n",
    "    store_sales.iloc[:, 6:].sum().rolling(30).mean().plot(label=d)\n",
    "plt.title('HOBBIES_1 sales by stores, rolling mean 30 days')\n",
    "plt.legend(loc=(1.0, 0.5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a definite increase of sales over time. And we can see that CA_1 and CA_3 stores have higher sales than other stores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sell_prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hobbies_1_prices = sell_prices.loc[sell_prices['item_id'].str.contains('HOBBIES_1')]\n",
    "plt.figure(figsize=(12, 6))\n",
    "for d in hobbies_1_prices['store_id'].unique():\n",
    "    small_df = hobbies_1_prices.loc[hobbies_1_prices['store_id'] == d]\n",
    "    grouped = small_df.groupby(['wm_yr_wk'])['sell_price'].mean()\n",
    "    plt.plot(grouped.index, grouped.values, label=d)\n",
    "plt.legend(loc=(1.0, 0.5))\n",
    "plt.title('HOBBIES_1 mean sell prices by store');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not only sales grow over time, the prices also grow. We can see that there were several points of time when the price increased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All info about a single state\n",
    "\n",
    "Now we can analyse how different items are sold in different stores of the same state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sales.loc[train_sales['state_id'] == 'CA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['item_id', 'dept_id', 'store_id']:\n",
    "    print(f\"{col} has {train_sales.loc[train_sales['state_id'] == 'CA', col].nunique()} unique values for CA state\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_sales = train_sales.loc[train_sales['state_id'] == 'CA']\n",
    "plt.figure(figsize=(12, 6))\n",
    "for d in ca_sales['store_id'].unique():\n",
    "    store_sales = ca_sales.loc[ca_sales['store_id'] == d]\n",
    "    store_sales.iloc[:, 6:].sum().rolling(30).mean().plot(label=d)\n",
    "plt.title('CA sales by stores, rolling mean 30 days')\n",
    "plt.legend(loc=(1.0, 0.5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a lot of interesting things:\n",
    "* ca_3 store always has higher sales;\n",
    "* ca_1 has a little increasing trend;\n",
    "* ca_2 had a long decline and then had a very steep increase in sales;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_prices = sell_prices.loc[sell_prices['store_id'].str.contains('CA')]\n",
    "plt.figure(figsize=(12, 6))\n",
    "for d in ca_prices['store_id'].unique():\n",
    "    small_df = ca_prices.loc[ca_prices['store_id'] == d]\n",
    "    grouped = small_df.groupby(['wm_yr_wk'])['sell_price'].mean()\n",
    "    plt.plot(grouped.index, grouped.values, label=d)\n",
    "plt.legend(loc=(1.0, 0.5))\n",
    "plt.title('Mean sell prices by store in CA');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there were several points of time when the price increased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregations over department\n",
    "\n",
    "Now let's look at various aggregations over the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "dept_grouped_sales = train_sales.groupby(['dept_id']).sum()\n",
    "for i, row in dept_grouped_sales.iterrows():\n",
    "    plt.plot(row.values, label=i);\n",
    "plt.legend(loc=(1.0, 0.5))\n",
    "plt.title('Sales by departments');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "for i, row in dept_grouped_sales.iterrows():\n",
    "    plt.plot(row.rolling(30).mean().values, label=i);\n",
    "plt.title('Sales by department, rolling mean 30 days')\n",
    "plt.legend(loc=(1.0, 0.5));\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "for i, row in dept_grouped_sales.iterrows():\n",
    "    plt.plot(row.rolling(60).mean().values, label=i);\n",
    "plt.title('Sales by department, rolling mean 60 days')\n",
    "plt.legend(loc=(1.0, 0.5));\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "for i, row in dept_grouped_sales.iterrows():\n",
    "    plt.plot(row.rolling(90).mean().values, label=i);\n",
    "plt.title('Sales by department, rolling mean 90 days')\n",
    "plt.legend(loc=(1.0, 0.5));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that `FOOD_3` has much higher sales than any other department."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
